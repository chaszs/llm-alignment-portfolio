
Each module documents a specific area of work, with its own methodology, scope, and examples.

---

## Modules

### ðŸ”¹ Alignment & Evaluation â€” Judge
**Status:** Completed

Hands-on experience evaluating LLM outputs using *LLM-as-a-Judge* frameworks.  
This module covers binary and Likert-based evaluation of factual accuracy, reasoning quality, instruction adherence, linguistic quality, pragmatic control, and safety.

ðŸ“‚ Module: `projects/01-alignment-judge/`  
ðŸ“„ Documentation:
- [README (ES)](projects/01-alignment-judge/README.md)
- [README (EN)](projects/01-alignment-judge/README_en.md)

---

### ðŸ”¹ Idioms & Semantic Analysis
**Status:** Planned / In progress

Linguistic analysis focused on idiomatic expressions, semantic variation, and meaning preservation.  
This module explores challenges related to non-literal language, paraphrasing, and semantic alignment in NLP systems.

ðŸ“‚ Module: `projects/02-idioms/`

---

### ðŸ”¹ Speech & ASR Evaluation
**Status:** Planned

Evaluation tasks related to speech data, transcription quality, and automatic speech recognition (ASR).  
The focus is on perceptual accuracy, annotation consistency, and language-specific challenges.

ðŸ“‚ Module: `projects/03-speech/`

---

## Methodological Principles

Across all modules, the work follows shared principles:

- Clear task scoping and evaluation criteria
- Explicit use of binary and Likert scales
- Attention to semantic and pragmatic correctness
- Emphasis on reasoning quality and explainability
- Awareness of safety and alignment constraints

---

## Purpose of the Repository

This repository serves as a professional portfolio to demonstrate:

- Practical experience in LLM evaluation and alignment
- Strong grounding in language, semantics, and reasoning
- Ability to apply structured evaluation frameworks
- Careful handling of edge cases and safety-sensitive tasks

The content is intended for technical reviewers, researchers, and teams working on NLP, alignment, or AI evaluation.



